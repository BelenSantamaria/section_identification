{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5ff0af4-0da0-45a6-abd7-dc6396eff79a",
   "metadata": {},
   "source": [
    "# **02-Reglas+Clasificación**\n",
    "\n",
    "Referencias\n",
    "\n",
    "* [Pysbd](https://github.com/nipunsadvilkar/pySBD/tree/master)\n",
    "* [Hyperparameter tuning transformers](https://huggingface.co/docs/transformers/hpo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4882fa06-e7de-401d-b193-827f483e3f73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/belensantamaria/Documentos/section_identification\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b47dada4-22a2-45fa-aaf9-d09de0b498cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import evaluate\n",
    "from transformers import TextClassificationPipeline\n",
    "\n",
    "import pysbd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a05ec3e-3285-45e3-bc13-3e7a41431dcd",
   "metadata": {},
   "source": [
    "## Creación del conjunto de datos para entrenar el clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aea43fc0-1690-4a30-857b-62daa20e4ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_df(file_path):\n",
    "\n",
    "    with open(file_path) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    entries = []\n",
    "    for note_id, entry in data[\"annotated_entries\"].items():\n",
    "        for annotation in entry[\"section_annotation\"][\"gold\"]:\n",
    "            d = {\n",
    "                \"text\": annotation[\"segment\"],\n",
    "                \"label\": annotation[\"label\"],\n",
    "            }\n",
    "            entries.append(d)\n",
    "        \n",
    "    df = pd.DataFrame(entries)    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcac0add-a5c5-403b-9de1-2e461ca4113f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = \"data/raw/clinais.train.json\"\n",
    "df_train = json_to_df(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57e7a743-1ad3-42ac-bf6b-bb6496d5ec47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>En Mayo de 1997, una mujer de 29 años de edad ...</td>\n",
       "      <td>PRESENT_ILLNESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>la ecografía y la tomografía axial computeriza...</td>\n",
       "      <td>EXPLORATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Se realizó resección completa de la tumoración...</td>\n",
       "      <td>TREATMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Treinta meses después, la paciente presentó en...</td>\n",
       "      <td>EVOLUTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>se reintervino y se llevó a cabo una resección...</td>\n",
       "      <td>TREATMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6471</th>\n",
       "      <td>por lo que precisó anticoagulación y retirada ...</td>\n",
       "      <td>TREATMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6472</th>\n",
       "      <td>A pesar de la utilización de la fistula arteri...</td>\n",
       "      <td>EVOLUTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6473</th>\n",
       "      <td>y por petición de la paciente, se replanteó vo...</td>\n",
       "      <td>TREATMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6474</th>\n",
       "      <td>Diariamente tiene una ultrafiltrafiltración co...</td>\n",
       "      <td>EVOLUTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6475</th>\n",
       "      <td>Las guías SEN recomiendan realizar reentrenami...</td>\n",
       "      <td>TREATMENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6476 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text            label\n",
       "0     En Mayo de 1997, una mujer de 29 años de edad ...  PRESENT_ILLNESS\n",
       "1     la ecografía y la tomografía axial computeriza...      EXPLORATION\n",
       "2     Se realizó resección completa de la tumoración...        TREATMENT\n",
       "3     Treinta meses después, la paciente presentó en...        EVOLUTION\n",
       "4     se reintervino y se llevó a cabo una resección...        TREATMENT\n",
       "...                                                 ...              ...\n",
       "6471  por lo que precisó anticoagulación y retirada ...        TREATMENT\n",
       "6472  A pesar de la utilización de la fistula arteri...        EVOLUTION\n",
       "6473  y por petición de la paciente, se replanteó vo...        TREATMENT\n",
       "6474  Diariamente tiene una ultrafiltrafiltración co...        EVOLUTION\n",
       "6475  Las guías SEN recomiendan realizar reentrenami...        TREATMENT\n",
       "\n",
       "[6476 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.to_json(\"data/rule/train.json\")\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed19adaa-7ce3-4f49-a55b-12d04396113a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df_train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5400e90-8bbe-40da-824c-ded4b1807df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"label\"] = le.transform(df_train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d921d1f-774c-4288-a4ea-dca7dbe8051c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>En Mayo de 1997, una mujer de 29 años de edad ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>la ecografía y la tomografía axial computeriza...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Se realizó resección completa de la tumoración...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Treinta meses después, la paciente presentó en...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>se reintervino y se llevó a cabo una resección...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6471</th>\n",
       "      <td>por lo que precisó anticoagulación y retirada ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6472</th>\n",
       "      <td>A pesar de la utilización de la fistula arteri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6473</th>\n",
       "      <td>y por petición de la paciente, se replanteó vo...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6474</th>\n",
       "      <td>Diariamente tiene una ultrafiltrafiltración co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6475</th>\n",
       "      <td>Las guías SEN recomiendan realizar reentrenami...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6476 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     En Mayo de 1997, una mujer de 29 años de edad ...      5\n",
       "1     la ecografía y la tomografía axial computeriza...      2\n",
       "2     Se realizó resección completa de la tumoración...      6\n",
       "3     Treinta meses después, la paciente presentó en...      1\n",
       "4     se reintervino y se llevó a cabo una resección...      6\n",
       "...                                                 ...    ...\n",
       "6471  por lo que precisó anticoagulación y retirada ...      6\n",
       "6472  A pesar de la utilización de la fistula arteri...      1\n",
       "6473  y por petición de la paciente, se replanteó vo...      6\n",
       "6474  Diariamente tiene una ultrafiltrafiltración co...      1\n",
       "6475  Las guías SEN recomiendan realizar reentrenami...      6\n",
       "\n",
       "[6476 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d8c9bd-57d0-4c2a-9ba7-134149d70ecb",
   "metadata": {},
   "source": [
    "## Creo secciones mediante reglas para el conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a333e4b-2075-4e62-8a81-dcd2df723b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"data/raw/clinais.dev.json\"\n",
    "\n",
    "with open(test_path) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "sections = []\n",
    "seg = pysbd.Segmenter(language=\"es\", clean=False, char_span=True)\n",
    "\n",
    "for note_id, entry in data[\"annotated_entries\"].items():\n",
    "    for sec in seg.segment(entry[\"note_text\"]):\n",
    "        d = {\n",
    "            \"note_id\": note_id,\n",
    "            \"text\": sec.sent,\n",
    "            # Necesito columna de label pero le pongo 0 a todo y luego lo cambio con las predicciones\n",
    "            \"label\": 0,\n",
    "            \"start_offset\": sec.start,\n",
    "            \"end_offset\": sec.end,\n",
    "        }\n",
    "        sections.append(d)\n",
    "\n",
    "df_test = pd.DataFrame(sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b68b89f6-c9f9-4e84-a83e-b4bea4f042cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0004-06142005000200009-3</td>\n",
       "      <td>Paciente de 69 a. de edad con un PSA en el mom...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0004-06142005000200009-3</td>\n",
       "      <td>El paciente tenía una biopsia previa por sexta...</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0004-06142005000200009-3</td>\n",
       "      <td>Se practicó una E-RME que mostró inicialmente ...</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004-06142005001000015-1</td>\n",
       "      <td>Un paciente varón de 19 años acudió al Servici...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0004-06142005001000015-1</td>\n",
       "      <td>No presentaba ningún antecedente urológico.</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>S1135-76062007000100006-1</td>\n",
       "      <td>La madre había fallecido súbitamente a los 48 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>S1135-76062007000100006-1</td>\n",
       "      <td>Una noche salió a cenar con los compañeros de ...</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>S1135-76062007000100006-1</td>\n",
       "      <td>No manifestó ninguna sintomatología y se acost...</td>\n",
       "      <td>0</td>\n",
       "      <td>369</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>S1135-76062007000100006-1</td>\n",
       "      <td>Poco después el perro comenzó a ladrar por lo ...</td>\n",
       "      <td>0</td>\n",
       "      <td>439</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>S1135-76062007000100006-1</td>\n",
       "      <td>Se avisó a los servicios de emergencia 061 que...</td>\n",
       "      <td>0</td>\n",
       "      <td>537</td>\n",
       "      <td>629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1989 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        note_id  \\\n",
       "0     S0004-06142005000200009-3   \n",
       "1     S0004-06142005000200009-3   \n",
       "2     S0004-06142005000200009-3   \n",
       "3     S0004-06142005001000015-1   \n",
       "4     S0004-06142005001000015-1   \n",
       "...                         ...   \n",
       "1984  S1135-76062007000100006-1   \n",
       "1985  S1135-76062007000100006-1   \n",
       "1986  S1135-76062007000100006-1   \n",
       "1987  S1135-76062007000100006-1   \n",
       "1988  S1135-76062007000100006-1   \n",
       "\n",
       "                                                   text  label  start_offset  \\\n",
       "0     Paciente de 69 a. de edad con un PSA en el mom...      0             0   \n",
       "1     El paciente tenía una biopsia previa por sexta...      0            79   \n",
       "2     Se practicó una E-RME que mostró inicialmente ...      0           140   \n",
       "3     Un paciente varón de 19 años acudió al Servici...      0             0   \n",
       "4          No presentaba ningún antecedente urológico.       0           112   \n",
       "...                                                 ...    ...           ...   \n",
       "1984  La madre había fallecido súbitamente a los 48 ...      0           180   \n",
       "1985  Una noche salió a cenar con los compañeros de ...      0           256   \n",
       "1986  No manifestó ninguna sintomatología y se acost...      0           369   \n",
       "1987  Poco después el perro comenzó a ladrar por lo ...      0           439   \n",
       "1988  Se avisó a los servicios de emergencia 061 que...      0           537   \n",
       "\n",
       "      end_offset  \n",
       "0             79  \n",
       "1            140  \n",
       "2            479  \n",
       "3            112  \n",
       "4            156  \n",
       "...          ...  \n",
       "1984         256  \n",
       "1985         369  \n",
       "1986         439  \n",
       "1987         537  \n",
       "1988         629  \n",
       "\n",
       "[1989 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c476d4-3b52-4995-bc8e-e99a6f3d0667",
   "metadata": {},
   "source": [
    "## Búsqueda hiperparámetros transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0de09ab0-279d-4d22-a6c3-87dd579dcb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"PlanTL-GOB-ES/roberta-base-biomedical-clinical-es\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdb1fe1f-23e8-4a8d-968c-00bef40a3007",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e17efd79-e3b2-4bd5-83d2-e864782e0036",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_train.label.unique().tolist()\n",
    "train, valid = train_test_split(df_train, test_size=0.2)\n",
    "\n",
    "dataset = DatasetDict()\n",
    "\n",
    "dataset[\"train\"] = Dataset.from_pandas(train)\n",
    "dataset[\"valid\"] = Dataset.from_pandas(valid)\n",
    "dataset[\"test\"] = Dataset.from_pandas(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7624ba5f-b08b-4114-b5e8-1c2d8f3d918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da806b2a-1cb6-4384-bef5-ab199e49db0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af5c2686985244b191440443307fe892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5180 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b9474dea824f799fe8621213169d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f8c07a6be24e0494fa7765c36d3ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1989 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_data = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "548694c8-38e6-4a15-92cd-5a91f69dc5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59a75d78-44b2-4df6-ab5b-8601e6871574",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/belensantamaria/opt/miniconda3/envs/ml/lib/python3.9/site-packages/transformers/training_args.py:1759: UserWarning: `use_mps_device` is deprecated and will be removed in version 5.0 of 🤗 Transformers.`mps` device will be used by default if available similar to the way `cuda` device is used.Therefore, no action from user is required. \n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-biomedical-clinical-es and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels = len(set(dataset[\"train\"][\"label\"]))\n",
    "\n",
    "metric_acc = evaluate.load(\"accuracy\")\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"data/rule\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    load_best_model_at_end=False,\n",
    "    save_total_limit=10,\n",
    "    use_mps_device=True,\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    return metric_acc.compute(predictions=preds, references=labels)\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=args,\n",
    "    train_dataset=encoded_data[\"train\"],\n",
    "    eval_dataset=encoded_data[\"valid\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "687a3ad7-f2df-4a9e-b6af-07c0c0f9acff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_space_optuna(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-4),\n",
    "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 1, 3),\n",
    "        \"seed\": trial.suggest_int(\"seed\", 1, 40),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0, 0.1),\n",
    "        \"lr_scheduler_type\": trial.suggest_categorical(\"lr_scheduler_type\", [\"cosine_with_restarts\", \"linear\"]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9002e5bc-e7ad-4f91-a877-6ec80470a800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-21 14:11:10,860] A new study created in memory with name: no-name-4ccffefd-d965-4104-ba31-f0d14cd2f45d\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-biomedical-clinical-es and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/belensantamaria/opt/miniconda3/envs/ml/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1296' max='1296' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1296/1296 1:27:00, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.506600</td>\n",
       "      <td>0.325485</td>\n",
       "      <td>0.909722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.223000</td>\n",
       "      <td>0.306686</td>\n",
       "      <td>0.928241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-21 15:38:16,213] Trial 0 finished with value: 0.9282407407407407 and parameters: {'learning_rate': 4.9989358625559586e-05, 'num_train_epochs': 2, 'seed': 38, 'weight_decay': 0.08984958679102431, 'lr_scheduler_type': 'cosine_with_restarts'}. Best is trial 0 with value: 0.9282407407407407.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-biomedical-clinical-es and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/belensantamaria/opt/miniconda3/envs/ml/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='648' max='648' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [648/648 47:17, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.478000</td>\n",
       "      <td>0.258592</td>\n",
       "      <td>0.924383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-21 16:25:39,496] Trial 1 finished with value: 0.9243827160493827 and parameters: {'learning_rate': 7.226361651030256e-05, 'num_train_epochs': 1, 'seed': 37, 'weight_decay': 0.05020773214857537, 'lr_scheduler_type': 'linear'}. Best is trial 0 with value: 0.9282407407407407.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-biomedical-clinical-es and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/belensantamaria/opt/miniconda3/envs/ml/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1296' max='1296' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1296/1296 1:25:41, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.524300</td>\n",
       "      <td>0.264780</td>\n",
       "      <td>0.925926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.235000</td>\n",
       "      <td>0.306378</td>\n",
       "      <td>0.925926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-21 17:51:27,022] Trial 2 finished with value: 0.9259259259259259 and parameters: {'learning_rate': 2.6822551582114098e-05, 'num_train_epochs': 2, 'seed': 16, 'weight_decay': 0.043659791302062156, 'lr_scheduler_type': 'linear'}. Best is trial 0 with value: 0.9282407407407407.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-biomedical-clinical-es and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/belensantamaria/opt/miniconda3/envs/ml/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1944' max='1944' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1944/1944 2:22:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.563300</td>\n",
       "      <td>0.384145</td>\n",
       "      <td>0.898920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.283900</td>\n",
       "      <td>0.343865</td>\n",
       "      <td>0.919753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.182300</td>\n",
       "      <td>0.370846</td>\n",
       "      <td>0.925926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-21 20:13:34,786] Trial 3 finished with value: 0.9259259259259259 and parameters: {'learning_rate': 8.6201919717379e-05, 'num_train_epochs': 3, 'seed': 6, 'weight_decay': 0.021857402537814354, 'lr_scheduler_type': 'cosine_with_restarts'}. Best is trial 0 with value: 0.9282407407407407.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-biomedical-clinical-es and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/belensantamaria/opt/miniconda3/envs/ml/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='648' max='648' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [648/648 47:37, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.465500</td>\n",
       "      <td>0.281827</td>\n",
       "      <td>0.914352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-21 21:01:18,190] Trial 4 finished with value: 0.9143518518518519 and parameters: {'learning_rate': 3.856308137687861e-05, 'num_train_epochs': 1, 'seed': 29, 'weight_decay': 0.08584661871656707, 'lr_scheduler_type': 'cosine_with_restarts'}. Best is trial 0 with value: 0.9282407407407407.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-biomedical-clinical-es and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/belensantamaria/opt/miniconda3/envs/ml/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='648' max='648' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [648/648 46:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.484300</td>\n",
       "      <td>0.269903</td>\n",
       "      <td>0.918981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-21 21:47:31,471] Trial 5 finished with value: 0.9189814814814815 and parameters: {'learning_rate': 7.354848730586093e-05, 'num_train_epochs': 1, 'seed': 12, 'weight_decay': 0.016830105494168756, 'lr_scheduler_type': 'cosine_with_restarts'}. Best is trial 0 with value: 0.9282407407407407.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-biomedical-clinical-es and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/belensantamaria/opt/miniconda3/envs/ml/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='648' max='648' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [648/648 46:20, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.514800</td>\n",
       "      <td>0.257811</td>\n",
       "      <td>0.927469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-21 22:33:57,357] Trial 6 finished with value: 0.9274691358024691 and parameters: {'learning_rate': 3.035442787101334e-05, 'num_train_epochs': 1, 'seed': 31, 'weight_decay': 0.028974526212703657, 'lr_scheduler_type': 'linear'}. Best is trial 0 with value: 0.9282407407407407.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-biomedical-clinical-es and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/belensantamaria/opt/miniconda3/envs/ml/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='648' max='1944' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 648/1944 45:42 < 1:31:41, 0.24 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.500800</td>\n",
       "      <td>0.353658</td>\n",
       "      <td>0.905093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-21 23:19:45,529] Trial 7 pruned. \n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-biomedical-clinical-es and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/belensantamaria/opt/miniconda3/envs/ml/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='648' max='1944' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 648/1944 42:26 < 1:25:07, 0.25 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.523900</td>\n",
       "      <td>0.456264</td>\n",
       "      <td>0.884259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-22 00:02:17,161] Trial 8 pruned. \n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-biomedical-clinical-es and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/belensantamaria/opt/miniconda3/envs/ml/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='648' max='648' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [648/648 41:37, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.526000</td>\n",
       "      <td>0.295898</td>\n",
       "      <td>0.906636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-22 00:43:59,639] Trial 9 pruned. \n"
     ]
    }
   ],
   "source": [
    "best_run = trainer.hyperparameter_search(hp_space=hp_space_optuna, n_trials=10, direction=\"maximize\", backend=\"optuna\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03b16a2d-abf9-4d58-85f6-df22058f1549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BestRun(run_id='0', objective=0.9282407407407407, hyperparameters={'learning_rate': 4.9989358625559586e-05, 'num_train_epochs': 2, 'seed': 38, 'weight_decay': 0.08984958679102431, 'lr_scheduler_type': 'cosine_with_restarts'}, run_summary=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c6d268-a89f-4550-bce9-56d569b0f7c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Predicción de las secciones del conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cabdf677-94ed-488f-bf5f-eeba4eb80b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"PlanTL-GOB-ES/roberta-base-biomedical-clinical-es\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "best_model = AutoModelForSequenceClassification.from_pretrained(\"data/rule/run-0/checkpoint-1000\")\n",
    "\n",
    "best_trainer = Trainer(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0beac165-75e7-48fc-879e-df93a49df7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions, labels, _ = best_trainer.predict(encoded_data[\"test\"])\n",
    "original_labels = le.inverse_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d501f3e-c495-47c9-884d-8c0491b89b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DERIVED_FROM/TO', 'DERIVED_FROM/TO', 'DERIVED_FROM/TO', ...,\n",
       "       'DERIVED_FROM/TO', 'DERIVED_FROM/TO', 'DERIVED_FROM/TO'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad322454-a36e-4c81-8eac-db6332b05f01",
   "metadata": {},
   "source": [
    "## Transformación de los segmentos y etiquetas para su evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d6ac1de-f2c0-4080-bc53-9d1d8f31125c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0004-06142005000200009-3</td>\n",
       "      <td>Paciente de 69 a. de edad con un PSA en el mom...</td>\n",
       "      <td>DERIVED_FROM/TO</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0004-06142005000200009-3</td>\n",
       "      <td>El paciente tenía una biopsia previa por sexta...</td>\n",
       "      <td>DERIVED_FROM/TO</td>\n",
       "      <td>79</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0004-06142005000200009-3</td>\n",
       "      <td>Se practicó una E-RME que mostró inicialmente ...</td>\n",
       "      <td>DERIVED_FROM/TO</td>\n",
       "      <td>140</td>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004-06142005001000015-1</td>\n",
       "      <td>Un paciente varón de 19 años acudió al Servici...</td>\n",
       "      <td>DERIVED_FROM/TO</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0004-06142005001000015-1</td>\n",
       "      <td>No presentaba ningún antecedente urológico.</td>\n",
       "      <td>DERIVED_FROM/TO</td>\n",
       "      <td>112</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>S1135-76062007000100006-1</td>\n",
       "      <td>La madre había fallecido súbitamente a los 48 ...</td>\n",
       "      <td>DERIVED_FROM/TO</td>\n",
       "      <td>180</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>S1135-76062007000100006-1</td>\n",
       "      <td>Una noche salió a cenar con los compañeros de ...</td>\n",
       "      <td>DERIVED_FROM/TO</td>\n",
       "      <td>256</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>S1135-76062007000100006-1</td>\n",
       "      <td>No manifestó ninguna sintomatología y se acost...</td>\n",
       "      <td>DERIVED_FROM/TO</td>\n",
       "      <td>369</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>S1135-76062007000100006-1</td>\n",
       "      <td>Poco después el perro comenzó a ladrar por lo ...</td>\n",
       "      <td>DERIVED_FROM/TO</td>\n",
       "      <td>439</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>S1135-76062007000100006-1</td>\n",
       "      <td>Se avisó a los servicios de emergencia 061 que...</td>\n",
       "      <td>DERIVED_FROM/TO</td>\n",
       "      <td>537</td>\n",
       "      <td>629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1989 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        note_id  \\\n",
       "0     S0004-06142005000200009-3   \n",
       "1     S0004-06142005000200009-3   \n",
       "2     S0004-06142005000200009-3   \n",
       "3     S0004-06142005001000015-1   \n",
       "4     S0004-06142005001000015-1   \n",
       "...                         ...   \n",
       "1984  S1135-76062007000100006-1   \n",
       "1985  S1135-76062007000100006-1   \n",
       "1986  S1135-76062007000100006-1   \n",
       "1987  S1135-76062007000100006-1   \n",
       "1988  S1135-76062007000100006-1   \n",
       "\n",
       "                                                   text            label  \\\n",
       "0     Paciente de 69 a. de edad con un PSA en el mom...  DERIVED_FROM/TO   \n",
       "1     El paciente tenía una biopsia previa por sexta...  DERIVED_FROM/TO   \n",
       "2     Se practicó una E-RME que mostró inicialmente ...  DERIVED_FROM/TO   \n",
       "3     Un paciente varón de 19 años acudió al Servici...  DERIVED_FROM/TO   \n",
       "4          No presentaba ningún antecedente urológico.   DERIVED_FROM/TO   \n",
       "...                                                 ...              ...   \n",
       "1984  La madre había fallecido súbitamente a los 48 ...  DERIVED_FROM/TO   \n",
       "1985  Una noche salió a cenar con los compañeros de ...  DERIVED_FROM/TO   \n",
       "1986  No manifestó ninguna sintomatología y se acost...  DERIVED_FROM/TO   \n",
       "1987  Poco después el perro comenzó a ladrar por lo ...  DERIVED_FROM/TO   \n",
       "1988  Se avisó a los servicios de emergencia 061 que...  DERIVED_FROM/TO   \n",
       "\n",
       "      start_offset  end_offset  \n",
       "0                0          79  \n",
       "1               79         140  \n",
       "2              140         479  \n",
       "3                0         112  \n",
       "4              112         156  \n",
       "...            ...         ...  \n",
       "1984           180         256  \n",
       "1985           256         369  \n",
       "1986           369         439  \n",
       "1987           439         537  \n",
       "1988           537         629  \n",
       "\n",
       "[1989 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"label\"] = original_labels\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e72c1ec6-43be-487d-892e-28cbc5b25147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entry_boundaries(df_test, note_id, boundaries):\n",
    "    temp_df = df_test[df_test[\"note_id\"]==note_id]\n",
    "    predictions = boundaries\n",
    "    for pred in predictions:\n",
    "        if pred[\"start_offset\"] in temp_df[\"start_offset\"].values:\n",
    "            pred[\"boundary\"] = temp_df[temp_df[\"start_offset\"]==pred[\"start_offset\"]][\"label\"].values[0]\n",
    "        else:\n",
    "            pred[\"boundary\"] = None\n",
    "    return predictions   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1052d34b-fc58-4693-8ef3-5baec76e3292",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"data/raw/clinais.dev.json\"\n",
    "\n",
    "with open(test_path) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "predictions = {}\n",
    "\n",
    "for note_id, entry in data[\"annotated_entries\"].items():\n",
    "    predictions[entry[\"note_id\"]] = entry\n",
    "    predictions[entry[\"note_id\"]][\"boundary_annotation\"][\"prediction\"] = entry_boundaries(df_test, note_id, entry[\"boundary_annotation\"][\"gold\"])\n",
    "    \n",
    "with open(\"data/predictions/predictions_rule_classsification.json\", \"w\") as f:\n",
    "    json.dump({\"annotated_entries\": predictions}, f)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
