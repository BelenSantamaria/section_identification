{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b394153f-dcb4-41ab-a490-89af0da38ee1",
   "metadata": {},
   "source": [
    "# **04.2-NER-Bert**\n",
    "\n",
    "References:\n",
    "* [Token Classification HuggingFace](https://huggingface.co/learn/nlp-course/chapter7/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ba3f6cf-1a9c-4139-8ef9-18a9f8f72641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/belensantamaria/Documentos/section_identification\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1021c139-1f86-4c6c-b363-cb9898b8e6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, DataCollatorForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import pipeline\n",
    "\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a95bb8b7-ee35-40ec-89a1-6c9a2828b0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_df(file_path, label2id):\n",
    "\n",
    "    with open(file_path) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    entries = []\n",
    "    for note_id, entry in data[\"annotated_entries\"].items():\n",
    "        text = entry[\"note_text\"]\n",
    "        tokens = re.findall(r\"\\w+|[^\\w\\s]\", text, re.UNICODE)\n",
    "        labels = np.zeros(len(tokens))\n",
    "        position = 0\n",
    "        for annotation in entry[\"section_annotation\"][\"gold\"]:\n",
    "            segment = annotation[\"segment\"]\n",
    "            segment_tokens = re.findall(r\"\\w+|[^\\w\\s]\", segment, re.UNICODE)\n",
    "            labels[position] =  label2id[annotation[\"label\"]]\n",
    "            position += len(segment_tokens)\n",
    "            \n",
    "        d = {\n",
    "            \"tokens\": tokens,\n",
    "            \"ner_tags\": labels.astype(int),\n",
    "        }    \n",
    "        entries.append(d)\n",
    "        \n",
    "    df = pd.DataFrame(entries)    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0a9eefd-cdaa-43c6-b7c6-45e0217aeb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\n",
    "    \"O\": 0,\n",
    "    \"EXPLORATION\": 1,\n",
    "    \"TREATMENT\": 2,\n",
    "    \"PRESENT_ILLNESS\": 3,\n",
    "    \"EVOLUTION\": 4,\n",
    "    \"PAST_MEDICAL_HISTORY\": 5,\n",
    "    \"DERIVED_FROM/TO\": 6,\n",
    "    \"FAMILY_HISTORY\": 7,\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a8d1d93-1a59-45ca-8282-f31045d6b92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"data/raw/clinais.train.json\"\n",
    "df_train = json_to_df(train_path, label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1cab815-9613-4976-b09c-ead6d633a6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[En, Mayo, de, 1997, ,, una, mujer, de, 29, añ...</td>\n",
       "      <td>[3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Varón, de, 66, años, controlado, en, Consulta...</td>\n",
       "      <td>[3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Mujer, de, 51, años, ,, monorrena, derecha, ,...</td>\n",
       "      <td>[3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Nuestra, paciente, es, una, mujer, de, 77, añ...</td>\n",
       "      <td>[3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Paciente, de, 68, años, de, edad, ,, con, ant...</td>\n",
       "      <td>[3, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>[Mujer, de, 26, años, con, ERC, secundaria, a,...</td>\n",
       "      <td>[3, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>[Varón, de, 41, años, con, ERC, estadio, V, de...</td>\n",
       "      <td>[3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>[Mujer, de, 83, años, con, insuficiencia, rena...</td>\n",
       "      <td>[3, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>[Presentamos, un, varón, de, 71, años, ,, con,...</td>\n",
       "      <td>[3, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>[Mujer, de, 74, años, con, enfermedad, renal, ...</td>\n",
       "      <td>[3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>781 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tokens  \\\n",
       "0    [En, Mayo, de, 1997, ,, una, mujer, de, 29, añ...   \n",
       "1    [Varón, de, 66, años, controlado, en, Consulta...   \n",
       "2    [Mujer, de, 51, años, ,, monorrena, derecha, ,...   \n",
       "3    [Nuestra, paciente, es, una, mujer, de, 77, añ...   \n",
       "4    [Paciente, de, 68, años, de, edad, ,, con, ant...   \n",
       "..                                                 ...   \n",
       "776  [Mujer, de, 26, años, con, ERC, secundaria, a,...   \n",
       "777  [Varón, de, 41, años, con, ERC, estadio, V, de...   \n",
       "778  [Mujer, de, 83, años, con, insuficiencia, rena...   \n",
       "779  [Presentamos, un, varón, de, 71, años, ,, con,...   \n",
       "780  [Mujer, de, 74, años, con, enfermedad, renal, ...   \n",
       "\n",
       "                                              ner_tags  \n",
       "0    [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1    [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2    [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3    [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, ...  \n",
       "4    [3, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "..                                                 ...  \n",
       "776  [3, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "777  [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "778  [3, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "779  [3, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "780  [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[781 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c842f70b-8d06-4b47-af7c-55dd71877768",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(df_train, test_size=0.2)\n",
    "\n",
    "dataset = DatasetDict()\n",
    "\n",
    "dataset[\"train\"] = Dataset.from_pandas(train, preserve_index=False)\n",
    "dataset[\"valid\"] = Dataset.from_pandas(valid, preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5c0cad2-f0e2-4d4a-86cc-e6ac9b7292b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "601f15e2-483a-4ba9-8525-e69a4e1873a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e314ef6ded114808857cbbe964450b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/624 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8664080fda4838a37dc012de0a2ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/157 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb3ccb26c7f4dc4becc694213ac3912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/127 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_checkpoint = \"PlanTL-GOB-ES/roberta-base-biomedical-clinical-es\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True, remove_columns=dataset[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "419ef013-0827-4b9b-892d-8d00aeb8fd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b18192be-fadc-4ac7-ac20-55439c0a6e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at PlanTL-GOB-ES/roberta-base-biomedical-clinical-es were not used when initializing RobertaForTokenClassification: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-biomedical-clinical-es and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ce62d94-9ec5-4a53-b5ca-b0378dd9f17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"data/NER/model\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    load_best_model_at_end=False,\n",
    "    save_total_limit=10,\n",
    "    use_mps_device=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c30a13f-e80e-4aa0-95a6-f2c7330461d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[id2label[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [id2label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffabe0f2-3626-4582-a299-831671c8d3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/belensantamaria/opt/miniconda3/envs/ml/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='780' max='780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [780/780 52:01, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.049559</td>\n",
       "      <td>0.987013</td>\n",
       "      <td>0.124897</td>\n",
       "      <td>0.221736</td>\n",
       "      <td>0.978889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.027346</td>\n",
       "      <td>0.699837</td>\n",
       "      <td>0.705012</td>\n",
       "      <td>0.702415</td>\n",
       "      <td>0.987746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.022329</td>\n",
       "      <td>0.750202</td>\n",
       "      <td>0.762531</td>\n",
       "      <td>0.756316</td>\n",
       "      <td>0.989712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.022032</td>\n",
       "      <td>0.725076</td>\n",
       "      <td>0.788825</td>\n",
       "      <td>0.755608</td>\n",
       "      <td>0.989578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.024817</td>\n",
       "      <td>0.811513</td>\n",
       "      <td>0.718159</td>\n",
       "      <td>0.761988</td>\n",
       "      <td>0.990437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.025201</td>\n",
       "      <td>0.733234</td>\n",
       "      <td>0.808546</td>\n",
       "      <td>0.769050</td>\n",
       "      <td>0.989998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.026461</td>\n",
       "      <td>0.788793</td>\n",
       "      <td>0.751849</td>\n",
       "      <td>0.769878</td>\n",
       "      <td>0.990284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.028324</td>\n",
       "      <td>0.779449</td>\n",
       "      <td>0.766639</td>\n",
       "      <td>0.772991</td>\n",
       "      <td>0.990609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.029393</td>\n",
       "      <td>0.772991</td>\n",
       "      <td>0.766639</td>\n",
       "      <td>0.769802</td>\n",
       "      <td>0.990303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.029288</td>\n",
       "      <td>0.780833</td>\n",
       "      <td>0.769926</td>\n",
       "      <td>0.775341</td>\n",
       "      <td>0.990571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/belensantamaria/opt/miniconda3/envs/ml/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRESENT_ILLNESS seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/Users/belensantamaria/opt/miniconda3/envs/ml/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: EXPLORATION seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/Users/belensantamaria/opt/miniconda3/envs/ml/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: TREATMENT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/Users/belensantamaria/opt/miniconda3/envs/ml/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PAST_MEDICAL_HISTORY seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/Users/belensantamaria/opt/miniconda3/envs/ml/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: EVOLUTION seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/Users/belensantamaria/opt/miniconda3/envs/ml/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DERIVED_FROM/TO seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/Users/belensantamaria/opt/miniconda3/envs/ml/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: FAMILY_HISTORY seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/Users/belensantamaria/opt/miniconda3/envs/ml/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/belensantamaria/opt/miniconda3/envs/ml/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRESENT_ILLNESS seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/Users/belensantamaria/opt/miniconda3/envs/ml/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: EXPLORATION seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/Users/belensantamaria/opt/miniconda3/envs/ml/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: TREATMENT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/Users/belensantamaria/opt/miniconda3/envs/ml/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PAST_MEDICAL_HISTORY seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/Users/belensantamaria/opt/miniconda3/envs/ml/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: EVOLUTION seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/Users/belensantamaria/opt/miniconda3/envs/ml/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DERIVED_FROM/TO seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/Users/belensantamaria/opt/miniconda3/envs/ml/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: FAMILY_HISTORY seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=780, training_loss=0.02481265251453106, metrics={'train_runtime': 3124.228, 'train_samples_per_second': 1.997, 'train_steps_per_second': 0.25, 'total_flos': 1625251915889280.0, 'train_loss': 0.02481265251453106, 'epoch': 10.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"valid\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "796c1da9-a27a-47ae-9b65-bf49aceab74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"data/NER/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d541e9c-4692-483a-8b65-6110f5d66491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_checkpoint = \"data/NER/model\"\n",
    "token_classifier = pipeline(\"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "106f82ab-0bce-4de9-9d45-07b068617649",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"data/raw/clinais.dev.json\"\n",
    "\n",
    "with open(test_path) as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9849dc3-7550-4edb-84bf-2f9c52946a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = []\n",
    "\n",
    "for note_id, entry in data[\"annotated_entries\"].items():\n",
    "    text = entry[\"note_text\"]\n",
    "    ents = token_classifier(text)\n",
    "\n",
    "    for ent in ents:\n",
    "        d = {\n",
    "            \"note_id\": note_id,\n",
    "            \"label\": ent[\"entity_group\"],\n",
    "            \"start_offset\": ent[\"start\"]\n",
    "        }\n",
    "        annotations.append(d)\n",
    "\n",
    "df = pd.DataFrame(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c12f14f1-4523-41f4-845c-184da99698af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note_id</th>\n",
       "      <th>label</th>\n",
       "      <th>start_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0004-06142005000200009-3</td>\n",
       "      <td>PRESENT_ILLNESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0004-06142005000200009-3</td>\n",
       "      <td>EXPLORATION</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0004-06142005001000015-1</td>\n",
       "      <td>PRESENT_ILLNESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004-06142005001000015-1</td>\n",
       "      <td>PAST_MEDICAL_HISTORY</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0004-06142005001000015-1</td>\n",
       "      <td>PRESENT_ILLNESS</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>S0376-78922009000400002-8</td>\n",
       "      <td>EVOLUTION</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>S1135-76062007000100006-1</td>\n",
       "      <td>PRESENT_ILLNESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>S1135-76062007000100006-1</td>\n",
       "      <td>FAMILY_HISTORY</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>S1135-76062007000100006-1</td>\n",
       "      <td>PRESENT_ILLNESS</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>S1135-76062007000100006-1</td>\n",
       "      <td>TREATMENT</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>941 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       note_id                 label  start_offset\n",
       "0    S0004-06142005000200009-3       PRESENT_ILLNESS             0\n",
       "1    S0004-06142005000200009-3           EXPLORATION           140\n",
       "2    S0004-06142005001000015-1       PRESENT_ILLNESS             0\n",
       "3    S0004-06142005001000015-1  PAST_MEDICAL_HISTORY           112\n",
       "4    S0004-06142005001000015-1       PRESENT_ILLNESS           154\n",
       "..                         ...                   ...           ...\n",
       "936  S0376-78922009000400002-8             EVOLUTION           741\n",
       "937  S1135-76062007000100006-1       PRESENT_ILLNESS             0\n",
       "938  S1135-76062007000100006-1        FAMILY_HISTORY           180\n",
       "939  S1135-76062007000100006-1       PRESENT_ILLNESS           256\n",
       "940  S1135-76062007000100006-1             TREATMENT           537\n",
       "\n",
       "[941 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5154424d-7860-4b4b-80e5-5a04078bb799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entry_boundaries(df_test, note_id, boundaries):\n",
    "    temp_df = df_test[df_test[\"note_id\"]==note_id]\n",
    "    predictions = boundaries\n",
    "    for pred in predictions:\n",
    "        if pred[\"start_offset\"] in temp_df[\"start_offset\"].values:\n",
    "            pred[\"boundary\"] = temp_df[temp_df[\"start_offset\"]==pred[\"start_offset\"]][\"label\"].values[0]\n",
    "        else:\n",
    "            pred[\"boundary\"] = None\n",
    "    return predictions   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3077397e-229f-432d-9256-39182a8414e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "\n",
    "for note_id, entry in data[\"annotated_entries\"].items():\n",
    "    predictions[entry[\"note_id\"]] = entry\n",
    "    predictions[entry[\"note_id\"]][\"boundary_annotation\"][\"prediction\"] = entry_boundaries(df, note_id, entry[\"boundary_annotation\"][\"gold\"])\n",
    "    \n",
    "with open(\"data/predictions/predictions_ner_bert.json\", \"w\") as f:\n",
    "    json.dump({\"annotated_entries\": predictions}, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ebb38b-1ae5-4faf-8fb0-3860644b759e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1440959-44ec-4641-ac3e-a9f3f9d548c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01e0d345-d37d-46a7-86b3-3fcfd801ba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[l for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [p for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b1ddfb-f035-491c-9f6e-60520db249ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
